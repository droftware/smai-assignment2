{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing modules\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import math\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(800, 100000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data file\n",
    "f = open(\"/home/tandon/IIIT-H/3rd/SMAI/dorothea/dorothea_train.data\")\n",
    "X = np.zeros((800, 100000))\n",
    "row = 0\n",
    "for line in f:\n",
    "    for token in line.split():\n",
    "        idx = int(token)\n",
    "        X[row, idx-1] = 1\n",
    "#         print(idx)\n",
    "    row += 1\n",
    "print('Done')\n",
    "f.close()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,)\n"
     ]
    }
   ],
   "source": [
    "# read the class labels associated with the training data\n",
    "f = open(\"/home/tandon/IIIT-H/3rd/SMAI/dorothea/dorothea_train.labels\")\n",
    "labels = np.zeros(800)\n",
    "i = 0\n",
    "for line in f:\n",
    "    digit = float(line.strip())\n",
    "    labels[i] = digit\n",
    "    i += 1\n",
    "print(labels.shape)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Shape (800, 1000)\n",
      "Number of positive samples 78\n",
      "Number of negative samples 722\n",
      "Shape of positive class (78, 1000)\n",
      "Shape of negative class (722, 1000)\n",
      "Shape of positive mean (1000,)\n",
      "Shape of negative mean (1000,)\n",
      "Shape of At positive (78, 1000)\n",
      "Shape of S_p (1000, 1000)\n",
      "Shape of At negative (722, 1000)\n",
      "Shape of S_n (1000, 1000)\n",
      "Shape of S_w (1000, 1000)\n",
      "Shape of inverse (1000, 1000)\n",
      "Shape of w (1000,)\n"
     ]
    }
   ],
   "source": [
    "# segregate data into +1 and -1 classes\n",
    "k = 1000\n",
    "Y = X[:, 0:k]\n",
    "print('Y Shape', Y.shape)\n",
    "bool_idx = (labels > 0)\n",
    "positive_class = Y[bool_idx, :]\n",
    "num_positive = positive_class.shape[0]\n",
    "print('Number of positive samples', num_positive)\n",
    "\n",
    "bool_idx = (labels < 0)\n",
    "negative_class = Y[bool_idx, :]\n",
    "num_negative = negative_class.shape[0]\n",
    "print('Number of negative samples', num_negative)\n",
    "\n",
    "print('Shape of positive class', positive_class.shape)\n",
    "print('Shape of negative class', negative_class.shape)\n",
    "\n",
    "positive_mean = positive_class.mean(0)\n",
    "negative_mean = negative_class.mean(0)\n",
    "\n",
    "print('Shape of positive mean', positive_mean.shape)\n",
    "print('Shape of negative mean', negative_mean.shape)\n",
    "\n",
    "At = positive_class - positive_mean\n",
    "print('Shape of At positive', At.shape)\n",
    "A = At.T\n",
    "S_p = A.dot(At)\n",
    "print('Shape of S_p', S_p.shape)\n",
    "\n",
    "\n",
    "At = negative_class - negative_mean\n",
    "print('Shape of At negative', At.shape)\n",
    "A = At.T\n",
    "S_n = A.dot(At)\n",
    "print('Shape of S_n', S_n.shape)\n",
    "\n",
    "S_w = S_p + S_n\n",
    "print('Shape of S_w',S_w.shape)\n",
    "\n",
    "S_w += S_w + np.identity(k)\n",
    "S_w.shape\n",
    "\n",
    "S_wi = np.linalg.inv(S_w)\n",
    "print('Shape of inverse', S_wi.shape)\n",
    "\n",
    "mean_dif = positive_mean- negative_mean\n",
    "w = S_wi.dot(mean_dif)\n",
    "print('Shape of w', w.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced x shape (800,)\n"
     ]
    }
   ],
   "source": [
    "reduced_X = w.T.dot(Y.T)\n",
    "print('Reduced x shape', reduced_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced_mean = np.mean(reduced_X)\n",
    "reduced_variance = np.var(reduced_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_multivariate(xi, mean = reduced_mean, variance = reduced_variance):\n",
    "    b1 = -1.0*(xi - mean)*(xi - mean)/(2*variance)\n",
    "    a1 = -0.5*np.log(2 * np.pi*variance) \n",
    "    final = a1 + b1\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculating prior probabilty values\n",
    "prior_positive = num_positive/800\n",
    "prior_negative = num_negative/800\n",
    "log_prior_positive = np.log(prior_positive)\n",
    "log_prior_negative = np.log(prior_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def positive_discriminant(x):\n",
    "    final = log_multivariate(x) + log_prior_positive\n",
    "    return final\n",
    "\n",
    "def negative_discriminant(x):\n",
    "    final = log_multivariate(x) + log_prior_negative\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, 350)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading validating data\n",
    "f = open(\"/home/tandon/IIIT-H/3rd/SMAI/dorothea/dorothea_valid.data\")\n",
    "V = np.zeros((350, 100000))\n",
    "row = 0\n",
    "for line in f:\n",
    "    for token in line.split():\n",
    "        idx = int(token)\n",
    "        V[row, idx-1] = 1\n",
    "#         print(idx)\n",
    "    row += 1\n",
    "print('Done')\n",
    "f.close()\n",
    "V = V[:,0:k]\n",
    "V = V.T\n",
    "V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350,)\n"
     ]
    }
   ],
   "source": [
    "# read the class labels associated with the training data\n",
    "f = open(\"/home/tandon/IIIT-H/3rd/SMAI/dorothea/dorothea_valid.labels\")\n",
    "v_labels = np.zeros(350)\n",
    "i = 0\n",
    "for line in f:\n",
    "    digit = float(line.strip())\n",
    "    v_labels[i] = digit\n",
    "    i += 1\n",
    "print(v_labels.shape)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of V (1000, 350)\n",
      "Shape of V_projected (350,)\n"
     ]
    }
   ],
   "source": [
    "# reduce dimension via LDA of the test data\n",
    "V_projected = w.T.dot(V)\n",
    "\n",
    "\n",
    "print('Shape of V', V.shape)\n",
    "print('Shape of V_projected', V_projected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct 316\n",
      "Percentage Correct:  90.28571428571428\n"
     ]
    }
   ],
   "source": [
    "# validating \n",
    "correct = 0\n",
    "for i in range(350):\n",
    "    x = V_projected[i]\n",
    "    if positive_discriminant(x) >= negative_discriminant(x):\n",
    "        if v_labels[i] > 0.0:\n",
    "            correct += 1\n",
    "    else:\n",
    "        if v_labels[i] < 0.0:\n",
    "            correct += 1\n",
    "print('Correct', correct)\n",
    "print('Percentage Correct: ', (correct/350*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Observation\n",
    "\n",
    "LDA worked better than PCA, which gave a max correctness of 89%\n",
    "Also the Sw was not invertible and to make it, we had to add an I matrix to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
